{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python392jvsc74a57bd009fc5894f378b07235dbf31045da37454dac7992a763f129049671a13badc12c",
   "display_name": "Python 3.9.2 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "09fc5894f378b07235dbf31045da37454dac7992a763f129049671a13badc12c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./data/merged-dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_network(df, from_hashtag=\"\", from_country=\"\"):\n",
    "    ''' returns a dataframe with the edges and timestamp from tweets feed (df)'''\n",
    "    \n",
    "    if from_hashtag != \"\":\n",
    "        mask = df[\"hashtags\"].apply(lambda x: from_hashtag.lower() in x)\n",
    "        filteredDf = df[mask]\n",
    "    else:\n",
    "        filteredDf = df\n",
    "\n",
    "    if from_country != \"\":\n",
    "        mask = filteredDf[\"country_code\"] == from_country\n",
    "        filteredDf = filteredDf[mask]\n",
    "\n",
    "    edges_df = filteredDf[['screen_name', 'to', 'created_at', 'text', 'followers_count', 'friends_count', 'favourites_count', 'retweet_count', 'toxicity']]\n",
    "    edges_df = edges_df.rename(columns={'screen_name': 'from'})\n",
    "    edges_df = edges_df.explode('to')\n",
    "    edges_df = edges_df.explode('to').reset_index(drop=True)\n",
    "    \n",
    "    edges_df[\"from\"] = edges_df[\"from\"].apply(lambda x: str(\"@\" + x) if len(x) != 0 and x[0] != \"@\" else x)\n",
    "    edges_df[\"to\"] = edges_df[\"to\"].apply(lambda x: str(\"@\" + x) if len(x) != 0 and x[0] != \"@\" else x)\n",
    "    \n",
    "    G = nx.from_pandas_edgelist(edges_df, 'from', 'to', [\"followers_count\", \"friends_count\", \"favourites_count\", \"retweet_count\", \"created_at\", \"text\", \"toxicity\"], create_using=nx.DiGraph())\n",
    "\n",
    "    return G\n",
    "\n",
    "# takes our main dataset and combines `reply_to_screen_name` and `mentions` from tweets\n",
    "# into a single `to` column\n",
    "# also drops tweets that don't have any mentiosn ore replying to someone\n",
    "# this should ALWAYS be used to get our primary data for the dataset\n",
    "def transform_df(df):\n",
    "    edges_df = df[['screen_name', 'reply_to_screen_name', 'created_at', 'hashtags', 'mentions', 'followers_count', 'friends_count', 'text', 'is_quote', 'is_retweet', 'favourites_count', 'retweet_count', 'country_code', 'verified', 'lang']]\n",
    "\n",
    "    edges_df[\"hashtags\"] = edges_df[\"hashtags\"].apply(lambda x: \",\".join(x))\n",
    "    edges_df[\"mentions\"] = edges_df[\"mentions\"].apply(lambda x: \",\".join(x))\n",
    "    \n",
    "    edges_df[\"reply_to_screen_name\"] = edges_df[\"reply_to_screen_name\"].fillna(\"\")\n",
    "    edges_df[\"reply_to_screen_name\"] = edges_df[\"reply_to_screen_name\"].apply(lambda x: \"@\" + x if x != \"\" else \"\")\n",
    "\n",
    "    edges_df[\"to\"] = edges_df[\"reply_to_screen_name\"] + \",\" + edges_df[\"mentions\"]\n",
    "    edges_df[\"to\"] = edges_df[\"to\"].fillna(\"\")\n",
    "\n",
    "    edges_df[\"to\"] = edges_df[\"to\"].apply(lambda x: \",\".join(list(set(x.split(\",\")))))\n",
    "    edges_df[\"to\"] = edges_df[\"to\"].apply(lambda x: x[1:] if len(x)>0 and x[0]==\",\" else x)\n",
    "\n",
    "    edges_df = edges_df.drop([\"reply_to_screen_name\", \"mentions\"], axis=1)\n",
    "    edges_df[\"country_code\"] = edges_df[\"country_code\"].fillna(\"\")\n",
    "\n",
    "    noReplyFilter = edges_df[\"to\"] != \"\"\n",
    "    edges_df = edges_df[noReplyFilter]\n",
    "\n",
    "    noRTFilter = edges_df[\"is_retweet\"] != True\n",
    "    edges_df = edges_df[noRTFilter]\n",
    "\n",
    "    onlyEnglishFilter = edges_df[\"lang\"] == \"en\"\n",
    "    edges_df = edges_df[onlyEnglishFilter]\n",
    "\n",
    "    rTfilters = edges_df[\"retweet_count\"] >= 50\n",
    "    edges_df = edges_df[rTfilters]\n",
    "\n",
    "    likefilters = edges_df[\"favourites_count\"] >= 50\n",
    "    edges_df = edges_df[likefilters]\n",
    "\n",
    "    edges_df = edges_df.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "    return edges_df\n",
    "\n",
    "def print_basic_stats(network):\n",
    "    print(\"Number of nodes: \" + str(network.number_of_nodes()))\n",
    "    print(\"Number of edges: \" + str(network.number_of_edges()))\n",
    "    print(\"Average clustering coefficient: \" + str(average_clustering(network)))\n",
    "\n",
    "    G_deg = nx.degree_histogram(G)\n",
    "    G_deg_sum = [a * b for a, b in zip(G_deg, range(0, len(G_deg)))]\n",
    "    print('Average degree: {}'.format(sum(G_deg_sum) / G.number_of_nodes()))\n",
    "\n",
    "    dirNet = network.to_undirected()\n",
    "    print(\"Network diameter: \" + str(diameter(dirNet)))\n",
    "    # print(\"Eigenvector centrality: \" + str(eigenvector_centrality(network)))\n",
    "    # print(\"Closeness centrality: \" + str(closeness_centrality(network)))\n",
    "\n",
    "def create_gephi_from_network(network, name):\n",
    "    nx.write_gexf(network, \"./gephis/\" + name + \"-network.gexf\")\n",
    "\n",
    "def get_strongly_gcc(G):\n",
    "    \"\"\" get the giant strongly connected component of G\"\"\" \n",
    "    SGcc = max(nx.strongly_connected_components(G), key=len)\n",
    "    SGcc = G.subgraph(SGcc)\n",
    "    return SGcc\n",
    "\n",
    "def get_weakly_gcc(G):\n",
    "    \"\"\" get the giant weakly connected component of G\"\"\"  \n",
    "    WGcc = max(nx.weakly_connected_components(G), key=len)\n",
    "    WGcc = G.subgraph(WGcc)\n",
    "    return WGcc\n",
    "   \n",
    "\n",
    "def plot_network(G, G_degree=None, outputname=\"default\", color=\"turquoise\", n_color=\"blue\"):\n",
    "    ''' plot the graph with varying nodesize '''\n",
    "    \n",
    "    fig = plt.figure(num=None, figsize=(15, 15), dpi=60, facecolor='b', edgecolor='k')\n",
    "    pos = nx.spring_layout(G)\n",
    "    \n",
    "    if G_degree:\n",
    "        node_size=[v * 10 for v in dict(G_degree).values()]\n",
    "    else:\n",
    "        node_size = 1\n",
    "        \n",
    "    nx.draw(G, pos, nodelist=dict(G_degree).keys(), node_size=node_size, width=0.5, alpha=0.5, edge_color=color, node_color=n_color)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    fig.savefig(\"./viz/\" +outputname + \"-network.svg\", transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyError",
     "evalue": "\"['toxicity', 'to'] not in index\"",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-d29fd8942dd3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mG\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mdegree_sequence\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0md\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mG\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdegree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-a647ccec36b9>\u001b[0m in \u001b[0;36mget_network\u001b[1;34m(df, from_hashtag, from_country)\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mfilteredDf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfilteredDf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0medges_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfilteredDf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'screen_name'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'to'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'created_at'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'text'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'followers_count'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'friends_count'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'favourites_count'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'retweet_count'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'toxicity'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m     \u001b[0medges_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0medges_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'screen_name'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'from'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0medges_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0medges_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexplode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'to'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3028\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3029\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3030\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3031\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3032\u001b[0m         \u001b[1;31m# take() does not accept boolean indexers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[1;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1264\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1265\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1266\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1267\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1268\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[1;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1314\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1315\u001b[0m                 \u001b[0mnot_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1316\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{not_found} not in index\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1317\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['toxicity', 'to'] not in index\""
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "G = get_network(df)\n",
    "\n",
    "degree_sequence = sorted([d for n, d in G.degree()], reverse=True)\n",
    "dmax = max(degree_sequence)\n",
    "\n",
    "plt.loglog(degree_sequence, \"b-\", marker=\"o\")\n",
    "plt.title(\"Degree rank plot\")\n",
    "plt.ylabel(\"degree\")\n",
    "plt.xlabel(\"rank\")\n",
    "\n",
    "# # draw graph in inset\n",
    "# plt.axes([0.45, 0.45, 0.45, 0.45])\n",
    "# Gcc = G.subgraph(sorted(nx.connected_components(G), key=len, reverse=True)[0])\n",
    "# pos = nx.spring_layout(Gcc)\n",
    "# plt.axis(\"off\")\n",
    "# nx.draw_networkx_nodes(Gcc, pos, node_size=20)\n",
    "# nx.draw_networkx_edges(Gcc, pos, alpha=0.4)\n",
    "# plt.show()"
   ]
  }
 ]
}